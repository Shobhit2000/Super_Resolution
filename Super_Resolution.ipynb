{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shobhit2000/Super_Resolution/blob/master/Super_Resolution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjpgocY0vbns"
      },
      "source": [
        "**Importing Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "649xkb1r8TcT"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.layers import Dense, Input, Conv2D, Flatten, Reshape, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras import backend as K"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTpnKZDqD0V3",
        "outputId": "87b1fe82-a6ee-48f6-c350-e906f3a12ac7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_VicYR6FKo-"
      },
      "source": [
        "**Data Prerpocessing Testing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTU22zMbBkyy"
      },
      "outputs": [],
      "source": [
        "# img = cv2.imread('test.jpg')\n",
        "# img_480 = cv2.resize(img, (640, 480))\n",
        "# img_144 = cv2.resize(img, (256, 144))\n",
        "# img_480_resize = cv2.resize(img_144, (640, 480))\n",
        "\n",
        "# cv2_imshow(img_480)\n",
        "# cv2_imshow(img_480_resize)\n",
        "\n",
        "# https://keras.io/examples/vision/super_resolution_sub_pixel/\n",
        "#  check this for preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7wChDlPvg4_"
      },
      "source": [
        "**Download Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6KaM0nikCwNG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb0e6fcf-7c7a-4eee-eab7-a4f823460b99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-09-23 06:31:45--  http://images.cocodataset.org/zips/test2017.zip\n",
            "Resolving images.cocodataset.org (images.cocodataset.org)... 52.217.173.81\n",
            "Connecting to images.cocodataset.org (images.cocodataset.org)|52.217.173.81|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6646970404 (6.2G) [application/zip]\n",
            "Saving to: ‘test2017.zip’\n",
            "\n",
            "test2017.zip        100%[===================>]   6.19G  12.8MB/s    in 8m 25s  \n",
            "\n",
            "2022-09-23 06:40:11 (12.6 MB/s) - ‘test2017.zip’ saved [6646970404/6646970404]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget http://images.cocodataset.org/zips/test2017.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QiAIpPiHpm58"
      },
      "outputs": [],
      "source": [
        "!unzip test2017.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsgWVGg4xB7h"
      },
      "source": [
        "**Parameters**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMcH73wdZBr1"
      },
      "source": [
        "**Generator MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "szbPFpMLM8kI"
      },
      "outputs": [],
      "source": [
        "def residual(temp_x):\n",
        "\n",
        "  conv_residual = layers.Conv2D(64, kernel_size=(3, 3), padding=\"same\", strides=1)(temp_x)\n",
        "  relu_residual = layers.ReLU()(conv_residual)\n",
        "  conv_residual = layers.Conv2D(64, kernel_size=(3, 3), padding=\"same\", strides=1)(relu_residual)\n",
        "\n",
        "  residual_block = tf.math.add(temp_x, conv_residual)\n",
        "\n",
        "  return residual_block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Lx6ywqnPxcT"
      },
      "outputs": [],
      "source": [
        "def generator_residual(temp_x):\n",
        "\n",
        "  x = layers.Conv2D(64, kernel_size=(3, 3), padding=\"same\", strides=1)(temp_x)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = layers.ReLU()(x)\n",
        "  x = layers.Conv2D(64, kernel_size=(3, 3), padding=\"same\", strides=1)(x)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  gen_residual_block = tf.math.add(temp_x, x)\n",
        "\n",
        "  return gen_residual_block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ol9CFSZnZEVS"
      },
      "outputs": [],
      "source": [
        "def generator_model(upscale_factor=2):\n",
        "\n",
        "  input = Input(shape=(144, 256, 3))\n",
        "  gen_base = layers.Conv2D(64, kernel_size=(9, 9), strides=1, padding=\"same\")(input)\n",
        "  gen_base = layers.ReLU()(gen_base)\n",
        "\n",
        "  gen_residual_block1 = generator_residual(gen_base)\n",
        "  gen_residual_block2 = generator_residual(gen_residual_block1)\n",
        "  gen_residual_block3 = generator_residual(gen_residual_block2)\n",
        "  gen_residual_block4 = generator_residual(gen_residual_block3)\n",
        "  gen_residual_block5 = generator_residual(gen_residual_block4)\n",
        "\n",
        "  gen_model = layers.Conv2D(64, kernel_size=(3, 3), strides=1, padding=\"same\")(gen_residual_block5)\n",
        "  gen_model = layers.BatchNormalization()(gen_model)\n",
        "  gen_model = tf.math.add(gen_base, gen_model)\n",
        "\n",
        "  gen_model = layers.Conv2D(256, kernel_size=(3, 3), strides=1, padding=\"same\")(gen_model)\n",
        "  # PIXEL_SHUFFLER\n",
        "  gen_model = layers.Conv2D(1 * (upscale_factor ** 2), kernel_size=(3, 3), strides=1, padding=\"same\")(gen_model)\n",
        "  gen_model = tf.nn.depth_to_space(gen_model, upscale_factor)\n",
        "  gen_model = layers.ReLU()(gen_model)\n",
        "\n",
        "  gen_model = layers.Conv2D(256, kernel_size=(3, 3), strides=1, padding=\"same\")(gen_model)\n",
        "  # PIXEL_SHUFFLER\n",
        "  gen_model = layers.Conv2D(1 * (upscale_factor ** 2), kernel_size=(3, 3), strides=1, padding=\"same\")(gen_model)\n",
        "  gen_model = tf.nn.depth_to_space(gen_model, upscale_factor)\n",
        "  gen_model = layers.ReLU()(gen_model)\n",
        "  gen_model = layers.Conv2D(3, kernel_size=(9, 9), strides=1, padding=\"same\")(gen_model)\n",
        "  gen_model_output = layers.Resizing(480, 640)(gen_model)\n",
        "  \n",
        "  gen_model = tf.keras.Model(inputs=input, outputs=gen_model_output, name=\"Super_Resolution_Generator\")\n",
        "  gen_model.summary()\n",
        "\n",
        "  return gen_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDG6JDRRjzY3"
      },
      "outputs": [],
      "source": [
        "# GENERATOR_MODEL = generator_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DKDAfTLmzJg"
      },
      "source": [
        "**Generator Architecture Diagram**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7tuO84H_mx4c"
      },
      "outputs": [],
      "source": [
        "# from tensorflow.keras.utils import plot_model\n",
        "\n",
        "# plot_model(GENERATOR_MODEL, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2zNOHYectRa"
      },
      "source": [
        "**Discriminator Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DPxgPdZ_cxcl"
      },
      "outputs": [],
      "source": [
        "def discriminator_model():\n",
        "\n",
        "  input = Input(shape=(480, 640, 3))\n",
        "  disc_model = layers.Conv2D(64, kernel_size=(3, 3), strides=1, padding=\"same\")(input)\n",
        "  disc_model = layers.LeakyReLU(alpha=0.2)(disc_model)\n",
        "\n",
        "  disc_block1 = layers.Conv2D(64, kernel_size=(3, 3), padding=\"same\", strides=2)(disc_model)\n",
        "  disc_block1 = layers.BatchNormalization()(disc_block1)\n",
        "  disc_block1 = layers.LeakyReLU(alpha=0.2)(disc_block1)\n",
        "\n",
        "  disc_block2 = layers.Conv2D(128, kernel_size=(3, 3), padding=\"same\", strides=1)(disc_block1)\n",
        "  disc_block2 = layers.BatchNormalization()(disc_block2)\n",
        "  disc_block2 = layers.LeakyReLU(alpha=0.2)(disc_block2)\n",
        "\n",
        "  disc_block3 = layers.Conv2D(128, kernel_size=(3, 3), padding=\"same\", strides=2)(disc_block2)\n",
        "  disc_block3 = layers.BatchNormalization()(disc_block3)\n",
        "  disc_block3 = layers.LeakyReLU(alpha=0.2)(disc_block3)\n",
        "\n",
        "  disc_block4 = layers.Conv2D(256, kernel_size=(3, 3), padding=\"same\", strides=1)(disc_block3)\n",
        "  disc_block4 = layers.BatchNormalization()(disc_block4)\n",
        "  disc_block4 = layers.LeakyReLU(alpha=0.2)(disc_block4)\n",
        "  \n",
        "  disc_block5 = layers.Conv2D(256, kernel_size=(3, 3), padding=\"same\", strides=2)(disc_block4)\n",
        "  disc_block5 = layers.BatchNormalization()(disc_block5)\n",
        "  disc_block5 = layers.LeakyReLU(alpha=0.2)(disc_block5)\n",
        "\n",
        "  disc_block6 = layers.Conv2D(512, kernel_size=(3, 3), padding=\"same\", strides=1)(disc_block5)\n",
        "  disc_block6 = layers.BatchNormalization()(disc_block6)\n",
        "  disc_block6 = layers.LeakyReLU(alpha=0.2)(disc_block6)\n",
        "  \n",
        "  disc_block7 = layers.Conv2D(512, kernel_size=(3, 3), padding=\"same\", strides=2)(disc_block6)\n",
        "  disc_block7 = layers.BatchNormalization()(disc_block7)\n",
        "  disc_block7 = layers.LeakyReLU(alpha=0.2)(disc_block7)\n",
        "\n",
        "  disc_model = GlobalAveragePooling2D()(disc_block7)\n",
        "  disc_model = layers.Dense(1024)(disc_model)\n",
        "  disc_model = layers.LeakyReLU(alpha=0.2)(disc_model)\n",
        "  disc_model_output = layers.Dense(1, activation='sigmoid')(disc_model)\n",
        "\n",
        "  disc_model = tf.keras.Model(inputs=input, outputs=disc_model_output, name=\"Super_Resolution_Discriminator\")\n",
        "  disc_model.summary()\n",
        "\n",
        "  return disc_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "secKRT2UKMr3"
      },
      "outputs": [],
      "source": [
        "# DISCRIMINATOR_MODEL = discriminator_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zl66oFUqKGVE"
      },
      "outputs": [],
      "source": [
        "# from tensorflow.keras.utils import plot_model\n",
        "\n",
        "# plot_model(DISCRIMINATOR_MODEL, to_file='model_plot_discriminator.png', show_shapes=True, show_layer_names=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def soft_dice_loss(y_true, y_pred, epsilon=1e-6): \n",
        "\n",
        "    # skip the batch and class axis for calculating Dice score\n",
        "    axes = tuple(range(1, len(y_pred.shape)-1)) \n",
        "    numerator = 2. * tf.math.reduce_sum(y_pred * y_true, axis=axes)\n",
        "    denominator = tf.math.reduce_sum(tf.math.square(y_pred) + tf.math.square(y_true), axes)\n",
        "    \n",
        "    return 1 - tf.math.reduce_mean(numerator / (denominator + epsilon)) # average over classes and batch"
      ],
      "metadata": {
        "id": "mDnJUhV5Xl7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gN7_JgGLRYM-"
      },
      "outputs": [],
      "source": [
        "def construct_models(verbose=False):\n",
        "\n",
        "    ### discriminator\n",
        "    DISCRIMINATOR_MODEL = discriminator_model()\n",
        "    DISCRIMINATOR_MODEL.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(lr=0.0001), metrics=['accuracy'])\n",
        "\n",
        "    ### generator\n",
        "    # do not compile generator\n",
        "    GENERATOR_MODEL = generator_model()\n",
        "    GENERATOR_MODEL.compile(loss=soft_dice_loss, optimizer=tf.keras.optimizers.Adam(lr=0.0001), metrics=['accuracy'])\n",
        "\n",
        "    ### SRGAN \n",
        "    SRGAN = tf.keras.Sequential()\n",
        "    SRGAN.add(GENERATOR_MODEL)\n",
        "    SRGAN.add(DISCRIMINATOR_MODEL)\n",
        "    DISCRIMINATOR_MODEL.trainable = False \n",
        "    SRGAN.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(lr=0.0001), metrics=['accuracy'])\n",
        "\n",
        "    # if verbose: \n",
        "    #     GENERATOR_MODEL.summary()\n",
        "    #     DISCRIMINATOR_MODEL.summary()\n",
        "    #     SRGAN.summary()\n",
        "        \n",
        "    return GENERATOR_MODEL, DISCRIMINATOR_MODEL, SRGAN\n",
        "  \n",
        "GENERATOR_MODEL, DISCRIMINATOR_MODEL, SRGAN = construct_models(verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXfMv9oGutPY"
      },
      "source": [
        "**Data Loader: Load images in batches to optimise memory**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sem0qZA5xFOF"
      },
      "outputs": [],
      "source": [
        "FILE_LIST = os.listdir('test2017')\n",
        "BATCH_SIZE = 16"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load models incase saved**"
      ],
      "metadata": {
        "id": "Uc7ObdMiC3Yc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GENERATOR_MODEL = tf.keras.models.load_model('drive/MyDrive/saved_model/generator.h5')\n",
        "DISCRIMINATOR_MODEL = tf.keras.models.load_model('drive/MyDrive/saved_model/discriminator.h5')\n",
        "SRGAN = tf.keras.models.load_model('drive/MyDrive/saved_model/srgan.h5')\n",
        "\n",
        "# Show the model architecture\n",
        "GENERATOR_MODEL.summary()\n",
        "DISCRIMINATOR_MODEL.summary()\n",
        "SRGAN.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "1BubXfI1C2vG",
        "outputId": "4707db5e-b6f1-4627-8c7b-d7f7501ba0c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-fef07cf8abdc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mGENERATOR_MODEL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'drive/MyDrive/saved_model/generator.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mDISCRIMINATOR_MODEL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'drive/MyDrive/saved_model/discriminator.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mSRGAN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'drive/MyDrive/saved_model/srgan.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Show the model architecture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    708\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m         raise ValueError(\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0;34mf'Unknown {printable_module_name}: {object_name}. Please ensure '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m             \u001b[0;34m'this object is passed to the `custom_objects` argument. See '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m             \u001b[0;34m'https://www.tensorflow.org/guide/keras/save_and_serialize'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unknown loss function: soft_dice_loss. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "236AtSbpr-kY"
      },
      "outputs": [],
      "source": [
        "def image_generator(files, batch_size):\n",
        "    \n",
        "    while True:\n",
        "          # Select files (paths/indices) for the batch\n",
        "          batch_paths  = np.random.choice(a    = files, \n",
        "                                          size = batch_size)\n",
        "          batch_input  = []\n",
        "          batch_output = [] \n",
        "          \n",
        "          # Read in each input, perform preprocessing and get labels\n",
        "          for input_path in batch_paths:\n",
        "              path = 'test2017/' + input_path\n",
        "              img = cv2.imread(path)                        # 480p image\n",
        "              img_480 = cv2.resize(img, (640, 480))\n",
        "              img_144 = cv2.resize(img, (256, 144))\n",
        "\n",
        "              img_480 = img_480/255\n",
        "              img_144 = img_144/255\n",
        "\n",
        "              batch_input.append(img_144)\n",
        "              batch_output.append(img_480)\n",
        "\n",
        "          batch_input = np.asarray(batch_input)\n",
        "          batch_output = np.asarray(batch_output)\n",
        "        \n",
        "          return batch_input, batch_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UciTBzK_2d3P",
        "outputId": "40d8d864-ecf5-43cd-ca43-438357d14a05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40670\n"
          ]
        }
      ],
      "source": [
        "print(len(FILE_LIST))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GAN Training**"
      ],
      "metadata": {
        "id": "1AFdXFSHNkiu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5PzsNx6DThNb"
      },
      "outputs": [],
      "source": [
        "# number of discriminator updates per alternating training iteration\n",
        "DISC_UPDATES = 1  \n",
        "# number of generator updates per alternating training iteration\n",
        "GAN_UPDATES = 1 \n",
        "PROGRESS_INTERVAL = 20 \n",
        "\n",
        "# function for training a GAN\n",
        "def run_training(generator, discriminator, gan, start_it=0, num_epochs=100):\n",
        "\n",
        "  # list for storing loss\n",
        "  avg_loss_discriminator = []\n",
        "  avg_loss_generator = []\n",
        "  avg_loss_srgan = []\n",
        "  total_it = start_it\n",
        "\n",
        "  # main training loop\n",
        "  for epoch in range(num_epochs):\n",
        "\n",
        "      ckpt.restore(manager.latest_checkpoint)\n",
        "      if manager.latest_checkpoint:\n",
        "        print(\"Restored from {}\".format(manager.latest_checkpoint))\n",
        "      else:\n",
        "        print(\"Initializing from scratch.\")\n",
        "\n",
        "      # alternating training loop\n",
        "      loss_discriminator = []\n",
        "      loss_generator = []\n",
        "      loss_srgan = []\n",
        "      print('Discriminator training')\n",
        "      for i in range(20): \n",
        "\n",
        "          # select a random set of real images\n",
        "          x_train, y_train = image_generator(FILE_LIST, BATCH_SIZE)\n",
        "\n",
        "          # generate a set of fake images using the generator\n",
        "          super_resolved_pred = generator.predict_on_batch(x_train)\n",
        "\n",
        "          #### DISCRIMINATOR training loop ####\n",
        "          for i in range(DISC_UPDATES): \n",
        "\n",
        "              #  Uncomment these 4 lines when value of DISC_UPDATES is greater than 1\n",
        "              # # select a random set of real images\n",
        "              # x_train, y_train = image_generator(FILE_LIST, BATCH_SIZE)\n",
        "\n",
        "              # # generate a set of fake images using the generator\n",
        "              # super_resolved_pred = generator.predict_on_batch(x_train)\n",
        "           \n",
        "              # train the discriminator on real images with label 1\n",
        "              true_labels = np.expand_dims(np.ones([BATCH_SIZE], dtype=np.float32), axis=1)\n",
        "              d_loss_real = discriminator.train_on_batch(y_train, true_labels)[1]\n",
        "              \n",
        "              # train the discriminator on fake images with label 0\n",
        "              fake_labels = np.expand_dims(np.zeros([BATCH_SIZE], dtype=np.float32), axis=1)\n",
        "              d_loss_fake = discriminator.train_on_batch(super_resolved_pred, fake_labels)[1]\n",
        "          \n",
        "          #### GENERATOR Training ####\n",
        "          gen_loss = generator.train_on_batch(x_train, y_train)[1]\n",
        "\n",
        "          # display some fake images for visual control of convergence\n",
        "          if total_it % PROGRESS_INTERVAL == 0:\n",
        "              plt.figure(figsize=(5,2))\n",
        "              batch_vis = min(BATCH_SIZE, 5)\n",
        "              x_train_visualize, y_train_visualize = image_generator(FILE_LIST, batch_vis)\n",
        "              super_resolved_pred_visualize = generator.predict_on_batch(x_train_visualize)\n",
        "              \n",
        "              for obj_plot in [super_resolved_pred_visualize, y_train_visualize]:\n",
        "                  plt.figure(figsize=(batch_vis * 3, 3))\n",
        "                  \n",
        "                  for b in range(batch_vis):\n",
        "                      disc_score = float(discriminator.predict_on_batch(np.expand_dims(obj_plot[b], axis=0))[0])\n",
        "                      plt.subplot(1, batch_vis, b + 1)\n",
        "                      plt.title(str(round(disc_score, 3)))\n",
        "                      plt.imshow(obj_plot[b] * 0.5 + 0.5) \n",
        "                 \n",
        "                  plt.show()  \n",
        "\n",
        "          #### SRGAN training loop ####\n",
        "          gan_loss = 0\n",
        "          y = np.ones([BATCH_SIZE, 1])\n",
        "          \n",
        "          for j in range(GAN_UPDATES):\n",
        "              # generate a set of random noise vectors\n",
        "              x_train, y_train = image_generator(FILE_LIST, BATCH_SIZE)\n",
        "              # train the generator on fake images with label 1\n",
        "              gan_loss += gan.train_on_batch(x_train, y)[1]\n",
        "\n",
        "          # store loss\n",
        "          loss_discriminator.append((d_loss_real + d_loss_fake) / 2.)\n",
        "          loss_generator.append(gen_loss)        \n",
        "          loss_srgan.append(gan_loss / GAN_UPDATES)\n",
        "          print(total_it)\n",
        "          total_it += 1\n",
        "\n",
        "      # visualize loss\n",
        "      print('Epoch', epoch)\n",
        "      print('Discriminator Loss:- ', str(np.mean(loss_discriminator)))\n",
        "      print('Generator Loss:- ', str(np.mean(loss_generator)))\n",
        "      print('SRGAN Loss:- ', str(np.mean(loss_srgan)))\n",
        "      avg_loss_discriminator.append(np.mean(loss_discriminator))\n",
        "      avg_loss_generator.append(np.mean(loss_generator))\n",
        "      avg_loss_srgan.append(np.mean(loss_srgan))\n",
        "      plt.plot(range(len(avg_loss_discriminator)), avg_loss_discriminator)\n",
        "      plt.plot(range(len(avg_loss_generator)), avg_loss_generator)\n",
        "      plt.plot(range(len(avg_loss_srgan)), avg_loss_srgan)\n",
        "      plt.legend(['Discriminator Loss', 'Generator Loss', 'SRGAN Loss'])\n",
        "      plt.show()\n",
        "\n",
        "      ckpt.step.assign_add(1)\n",
        "      if int(ckpt.step) % 1 == 0:\n",
        "        save_path = manager.save()\n",
        "        print(\"Saved checkpoint for step {}: {}\".format(int(ckpt.step), save_path))\n",
        "        print(\"loss {:1.2f}\".format(gan_loss))\n",
        "\n",
        "  return generator, discriminator, gan"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ckpt = tf.train.Checkpoint(step=tf.Variable(1))\n",
        "manager = tf.train.CheckpointManager(ckpt, '/content/drive/MyDrive/Video_Enhancer/DL_Models/SRGAN/tf_ckpts', max_to_keep=1)\n",
        "\n",
        "generator_celeb, discriminator_celeb, gan_celeb = run_training(GENERATOR_MODEL, DISCRIMINATOR_MODEL, SRGAN, \n",
        "                                                               num_epochs=100)"
      ],
      "metadata": {
        "id": "K0dxqJyZm_LC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Test**"
      ],
      "metadata": {
        "id": "L1wzOC1wNYOE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LTAsoYykNKNb"
      },
      "outputs": [],
      "source": [
        "x_train_visualize, y_train_visualize = image_generator(FILE_LIST, 1)\n",
        "super_resolved_pred_visualize = GENERATOR_MODEL.predict_on_batch(x_train_visualize)\n",
        "\n",
        "cv2_imshow(super_resolved_pred_visualize[0]*255)\n",
        "cv2_imshow(y_train_visualize[0]*255)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Save Model**"
      ],
      "metadata": {
        "id": "8Wp-Tx96l9J0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GENERATOR_MODEL.save('drive/MyDrive/saved_model/generator.h5')\n",
        "DISCRIMINATOR_MODEL.save('drive/MyDrive/saved_model/discriminator.h5')\n",
        "SRGAN.save('drive/MyDrive/saved_model/srgan.h5')"
      ],
      "metadata": {
        "id": "IMVrSth9l8YD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load Model**"
      ],
      "metadata": {
        "id": "gMuA7eh1mjq2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GENERATOR_MODEL = tf.keras.models.load_model('drive/MyDrive/saved_model/generator.h5')\n",
        "DISCRIMINATOR_MODEL = tf.keras.models.load_model('drive/MyDrive/saved_model/discriminator.h5')\n",
        "SRGAN = tf.keras.models.load_model('drive/MyDrive/saved_model/srgan.h5')\n",
        "\n",
        "# Show the model architecture\n",
        "GENERATOR_MODEL.summary()\n",
        "DISCRIMINATOR_MODEL.summary()\n",
        "SRGAN.summary()"
      ],
      "metadata": {
        "id": "RJCueMbjvA-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iHUAcmxK5ojZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}